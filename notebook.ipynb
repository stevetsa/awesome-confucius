{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a76f10d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 scikit-learn nltk pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae896549",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcac5f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def is_same_domain(base_url, link):\n",
    "    return urlparse(base_url).netloc == urlparse(link).netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba2a5b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def crawl_site(base_url, keywords, max_pages=50, delay=1):\n",
    "    visited = set()\n",
    "    to_visit = [base_url]\n",
    "    results = []\n",
    "\n",
    "    keywords = [k.lower() for k in keywords]\n",
    "\n",
    "    while to_visit and len(results) < max_pages:\n",
    "        url = to_visit.pop(0)\n",
    "        if url in visited:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            visited.add(url)\n",
    "\n",
    "            text = clean_text(soup.get_text())\n",
    "\n",
    "            if any(k in text for k in keywords):\n",
    "                results.append({\n",
    "                    \"url\": url,\n",
    "                    \"content\": text[:5000]  # limit size\n",
    "                })\n",
    "\n",
    "            for link in soup.find_all(\"a\", href=True):\n",
    "                full_url = urljoin(base_url, link[\"href\"])\n",
    "                if is_same_domain(base_url, full_url):\n",
    "                    if full_url not in visited and full_url not in to_visit:\n",
    "                        to_visit.append(full_url)\n",
    "\n",
    "            time.sleep(delay)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0dec0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def categorize_content(df, n_categories=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
    "    X = vectorizer.fit_transform(df[\"content\"])\n",
    "\n",
    "    model = KMeans(n_clusters=n_categories, random_state=42)\n",
    "    df[\"category\"] = model.fit_predict(X)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb233b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# USER INPUT\n",
    "base_url = input(\"Enter website URL (e.g. https://example.com): \").strip()\n",
    "keywords = input(\"Enter keywords (comma separated): \").split(\",\")\n",
    "\n",
    "keywords = [k.strip() for k in keywords]\n",
    "\n",
    "# CRAWL\n",
    "df = crawl_site(base_url, keywords)\n",
    "\n",
    "print(f\"Collected {len(df)} relevant pages\")\n",
    "\n",
    "# CATEGORIZE\n",
    "df = categorize_content(df)\n",
    "\n",
    "df[[\"url\", \"category\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67583a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for cat in sorted(df[\"category\"].unique()):\n",
    "    print(f\"\\nðŸ”¹ Category {cat}\")\n",
    "    display(df[df[\"category\"] == cat][[\"url\"]])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
